latex symbols to consider
\bigvee
\bigwedge

Model outline

	Initialization
		Model is initialized with init(active_node) = -1.
	Steps
		If the active_node = -1, then check if we need to resume a previous run. If we do, see resume section. Otherwise, next(active_node) = 0.
		If the active_node is a leaf node, the active_node returns to the leaf nodes parent.
		If the active_node is decorator node, check if previous_node < active_node. If so, we need to visit the child. If not, return to the parent.
		If the active_node is a sequence node, check if previous_node



Resume structure

Resuming when there are no parallel nodes is very simple. Instead of starting at the root of the tree, the tree jumps to whichever leaf node triggered the Running result, and traversal continues as normal from that point. If there are parallel nodes, resuming is much more involved.





Naive tree encoding

Each node is in one of 4 states: Running, Success, Failure, or Invalid, where the first 3 are the results of running a node and the 4th is for internal use. A naive encoding, then, involves each node storing a status variable which can be any of these 4 states. By combining this with an active_node variable, you can traverse the tree with some basic logic, updating each nodes status only when it is the active_node. Note that additional 'constant' information, such as which node is a node's parent, can be stored using Define macros. Define macros do not increase the size of the models. Unfortunately, even with Define macros this has at least n*4^n states (n from active_node, 4 from each status of which there are 4^n).

A slight optimization on this model involves realizing that all internal nodes are completely deterministic and as such, their statuses don't need to be stored, as their information can be reconstructed from the statuses of other nodes. Thus we can improve upon the previous iteration by storing only the statuses of the leaf nodes, and using Define macros for the internal node statuses. This lowers the state size to n*4^l, where l is the number of leaf nodes.

A further slight optimization involves ensuring the nodes are ordered in a Depth First Traversal order, which allows us to eliminate the active_node variable, as we can now simply jump to the relevant leaf node by considering the active node to be the first leaf node whose status is Invalid, dropping the value further down to 4^l.

Advanced Tree Encoding

The problem with all these encodings, is that they do not utilize the structure of the tree. Consider the following tree, and assume that the indicated node is active. Note then, that since this node is active, we know a lot about the rest of the tree. Since the parent node is a Selector node, we know that nodes X and Y must have most recently returned Failure. If they had returned Success or Running, then the selector node would have returned instead of continuing to run this node. Let us consider, then, how we could encode a model by exploiting the structure of the tree itself.

First consider a tree without parallel nodes. If the active node is a leaf node, then the next active node will always be the parent. If the active node is a selector, status, or decorator* node, then the next acive node is determined through a combination of the previous node, the previous node's status, and static information (such as what the node's children and parent are). Based on this, let us consider a new model which stores the active node, previous active node, and the previous node's status.




Parallel Resume

Unfortunately, while the prior encoding works well for trees without parallel nodes, it fails when they are introduced. Suppose we tried resuming in the same fashion as before. If we resume in a leaf node that is
The problems are that the behavior of a parallel node is different when resuming a run then when starting fresh and that multiple nodes may have been left in a running state, where previously there was a single running source.
Consider a tree with a parallel node as it's root, and no other parallel nodes. If we remove the parallel node, then we have a forest with no parallel nodes, and we already have an efficient Resume strategy for trees with no parallel nodes. Therefore, we can reuse that Resume strategy, storing a value for each child of the parallel node. We can then expand this to work with trees in general. First let us consider the case where the parallel node is not the root. In this case, if the parallel node returns running, then we need to resume from the parallel node, and begin using.
Consider again the tree with a parallel node as it's root, and no other parallel nodes. Let us now replace one of the children with a parallel node like so. We know how the new parallel node will resume, but how does this affect the resume of the





Sequence Nodes

Sequence Nodes run their children in order. There are three conditions under which a Sequence Node will return a value.
1. A child returned Failure. In this case, the Sequence Node returns Failure.
2. A child returned Running. In this case, the Sequence Node returns Running.
3. All children returned Success. In this case, the Sequence Node returns Success.
When a Sequence Node Resumes after returning Running, it will not rerun any children that had already returned success.


Selector Nodes

Selector Nodes run their children in order. There are three conditions under which a Selector Node will return a value.
1. A child returned Success. In this case, the Selector Node returns Success.
2. A child returned Running. In this case, the Selector Node returns Running.
3. All children returned Failure. In this case, the Selector Node returns Failure.
When a Selector Node Resumes after returning Running, it will start with it's first child, regardless of what it previously returned. The child that returned running will be resumed.


Parallel Nodes

There are 2 kinds of parallel Nodes: Synchronized and Unsynchronized. Both run their children in order.  They will only return a value once all their children have returned a value, with the following conditions.
1. If any child returned Failure, the Parallel Node will return Failure.
2. If no children returned Failure and the set of children that returned Success was satisfactory, the Parallel Node will return Success.
3. If no children returned Failure and the set of children that returned Success was unsatisfactory, the Parallel Node will return Running.
A set is satisfactory if it satisfies the policy of the Parallel Node. py_trees provides two built-in basic policies, SuccessOnOne and SuccessOnAll. SuccessOnOne requires that at least one child return Success, while SuccessOnAll requires all children to return Success. py_trees also allows the user to specify a list of children under the SuccessOnSelected policy. In this case, the parallel node will only return success if all children in the specified list return Success. While no other policies are directly supported by py_trees, one could modify the parallel class to accept sets of sets of children, such that the Parallel Node returns Success if and only if the set of children that returned success belongs to the set of sets the Parallel node was created with.
The difference between Synchronized and Unsynchronized nodes lies in how they Resume after returning Running. A Synchronized Parallel Node will not rerun any children that returned Success, and will instead resume only the children that returned Running. An Unsynchronized Parallel Node will rerun any children that returned Success and resume any children that returned Running. 